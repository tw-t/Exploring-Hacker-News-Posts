{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will be focused on exploring a data set of posts submitted to the [Hacker News](https://news.ycombinator.com/) website for 12 months up to September 2016.\n",
    "\n",
    "The two questions we are interested in answering are:\n",
    "* Do Ask HN or Show HN receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "Note that the data set has been reduced from the original 300,000 rows (approx.) to 20,000 rows after removing submissions that received no comments then conducting random sampling.\n",
    "\n",
    "Please find further documentation to the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and read data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']]\n",
      "293120\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "opened_file = open(r'C:\\Users\\tsa19\\Dataquest Projects\\Datasets\\HN_posts_year_to_Sep_26_2016.csv', encoding=\"utf8\")\n",
    "read_file = csv.reader(opened_file)\n",
    "hn_raw = list(read_file)\n",
    "\n",
    "## Display first five rows of data set ##\n",
    "print(hn_raw[:5])\n",
    "print(len(hn_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12000858',\n",
       "  'How Amazon Triggered a Robot Arms Race',\n",
       "  'http://www.bloomberg.com/news/articles/2016-06-29/how-amazon-triggered-a-robot-arms-race',\n",
       "  '164',\n",
       "  '101',\n",
       "  'petethomas',\n",
       "  '6/29/2016 11:22'],\n",
       " ['10329616',\n",
       "  'Girls in Tech employee fired for misogynist email rant',\n",
       "  'http://recode.net/2015/10/04/girls-in-tech-employee-fired-for-misogynist-email-rant/',\n",
       "  '5',\n",
       "  '8',\n",
       "  'pavornyoh',\n",
       "  '10/5/2015 2:07'],\n",
       " ['12295633',\n",
       "  'How PayPal Scaled to Billions of Transactions Daily Using Just 8VMs',\n",
       "  'http://highscalability.com/blog/2016/8/15/how-paypal-scaled-to-billions-of-transactions-daily-using-ju.html',\n",
       "  '7',\n",
       "  '1',\n",
       "  'yarapavan',\n",
       "  '8/16/2016 5:01'],\n",
       " ['11488759',\n",
       "  'Calculating PI with bc',\n",
       "  'http://alien.slackbook.org/blog/calculating-pi/',\n",
       "  '3',\n",
       "  '2',\n",
       "  'vmorgulis',\n",
       "  '4/13/2016 15:05'],\n",
       " ['12064749',\n",
       "  'Ask HN: What salary will make you move to bay area?',\n",
       "  '',\n",
       "  '2',\n",
       "  '1',\n",
       "  'RestlessMind',\n",
       "  '7/10/2016 6:18']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first row as headers\n",
    "headers = hn_raw[0]\n",
    "hn_data = hn_raw[1:]\n",
    "\n",
    "# Removing data with no comments\n",
    "hn = []\n",
    "\n",
    "for row in hn_data:\n",
    "    num_comments = row[4]\n",
    "    if num_comments != '0': # Only adding entry to list if number of comments is not 0.\n",
    "        hn.append(row)\n",
    "\n",
    "# import random module\n",
    "import random\n",
    "\n",
    "# Select random 20,000 entries from data set\n",
    "random.seed(1) # initialise a random number generator for data replicability\n",
    "hn = random.sample(hn, 20000)\n",
    "\n",
    "# Display headers and checking extraction complete\n",
    "print(headers)\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN entries: 1765\n",
      "Show HN entries: 1194\n",
      "Other entries: 17041\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print('Ask HN entries:', len(ask_posts))\n",
    "print('Show HN entries:', len(show_posts))\n",
    "print('Other entries:', len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average number of comments for Ask HN and Show HN entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ask HN comments: 13.120679886685553\n",
      "Average Show HN comments: 9.403685092127303\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "# Finding sum of comments for Ask HN posts\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print('Average Ask HN comments:', avg_ask_comments)\n",
    "\n",
    "# Finding sum of comments for Show HN posts\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print('Average Show HN comments:', avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are, on average, 39.53% more comments for Ask HN posts (13 comments per post) compared to Show HN posts (9 comments per post)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding amount of Ask posts and comments by hour created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime module\n",
    "import datetime as dt\n",
    "\n",
    "# create list to store time and number of comments each entry in Ask HN list have\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    create_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([create_at, num_comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    dt_object = dt.datetime.strptime(row[0], \"%m/%d/%Y %H:%M\") # parse first element into datetime object\n",
    "    dt_string = dt_object.strftime(\"%H\") # select hour of each entry and rewrite as string\n",
    "    \n",
    "    if dt_string in counts_by_hour:\n",
    "        counts_by_hour[dt_string] += 1\n",
    "        comments_by_hour[dt_string] += row[1]\n",
    "    else:\n",
    "        counts_by_hour[dt_string] = 1\n",
    "        comments_by_hour[dt_string] = row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating average number of posts for Ask HN by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['06', 10.701754385964913],\n",
       " ['14', 13.195402298850574],\n",
       " ['13', 20.773809523809526],\n",
       " ['22', 10.708333333333334],\n",
       " ['20', 9.770642201834862],\n",
       " ['09', 10.218181818181819],\n",
       " ['07', 7.658536585365853],\n",
       " ['21', 11.242990654205608],\n",
       " ['15', 43.206896551724135],\n",
       " ['10', 10.948275862068966],\n",
       " ['12', 19.873015873015873],\n",
       " ['02', 7.603448275862069],\n",
       " ['03', 13.777777777777779],\n",
       " ['04', 7.644444444444445],\n",
       " ['18', 9.858333333333333],\n",
       " ['16', 10.363636363636363],\n",
       " ['11', 6.974683544303797],\n",
       " ['17', 10.288659793814434],\n",
       " ['05', 8.51063829787234],\n",
       " ['19', 10.14018691588785],\n",
       " ['00', 9.017543859649123],\n",
       " ['23', 6.258620689655173],\n",
       " ['01', 8.73076923076923],\n",
       " ['08', 16.576923076923077]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour] / counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and printing values from list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 43.21 average comments per post\n",
      "13:00: 20.77 average comments per post\n",
      "12:00: 19.87 average comments per post\n",
      "08:00: 16.58 average comments per post\n",
      "03:00: 13.78 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]]) # reverse the order of elements in list\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True) # sorting list in descending order by average post\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for avg, hour in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{}: {:.2f} average comments per post\".format(\n",
    "            dt.datetime.strptime(hour, \"%H\").strftime(\"%H:%M\"), avg\n",
    "        )\n",
    "    ) # printing results in specified format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Ask HN posts posted at the hour between 15:00 and 16:00 receive the most replies at 43.21 comments per post, which is more than thrice the average post created at random time.\n",
    "The second busiest hour is between 13:00-14:00, where there are 20.77 replies on average. This is 58.31% higher than the unspecified time average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating average number of posts for Ask HN by hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time zone for the date and time the post was made is in Eastern Time in the US (UTC -5) and my local time zone is UTC +8, hence, I will need to add 13 hours to the printed hours above for a localised answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the logic above, the top 5 hours with most comments to post in my local time (UTC +8) are:\n",
      "04:00: 43.21 average comments per post\n",
      "02:00: 20.77 average comments per post\n",
      "01:00: 19.87 average comments per post\n",
      "21:00: 16.58 average comments per post\n",
      "16:00: 13.78 average comments per post\n"
     ]
    }
   ],
   "source": [
    "local_sorted_swap = sorted_swap.copy() # use copied data to perform transformation on\n",
    "\n",
    "for row in local_sorted_swap:\n",
    "    dt_object = dt.datetime.strptime(row[1], \"%H\") # parse first element into datetime object\n",
    "    dt_local = dt_object + dt.timedelta(hours=13) # Add 13 hours to original time\n",
    "    dt_string = dt_local.strftime(\"%H\") # select hour of each entry and rewrite as string\n",
    "    row[1] = dt_string\n",
    "    \n",
    "print(\"Using the logic above, the top 5 hours with most comments to post in my local time (UTC +8) are:\")\n",
    "\n",
    "for avg, hour in local_sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{}: {:.2f} average comments per post\".format(\n",
    "            dt.datetime.strptime(hour, \"%H\").strftime(\"%H:%M\"), avg\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wish to maximise the number of comments to an Ask HN post, they should post between 3pm EST to 4pm EST or at 6am UTC +8 to 7am UTC +8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible further questions to investigate:\n",
    "* Determine if show or ask posts receive more points on average\n",
    "* Determine if posts created at a certain time are more likely to receive more points\n",
    "* Compare your results to the average number of comments and points other posts receive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
